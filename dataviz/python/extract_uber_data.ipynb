{
 "metadata": {
  "name": "",
  "signature": "sha256:6e35f45f3e23084bd80483144177009d6d79f7f4ac16a96b71e50a9bc01fa962"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Extract data from Uber Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "README: Uber GPS Traces (June 2011)\n",
      "\n",
      "This collection contains gps logs from black car pickups in San Francisco. It is intended for data visualization purposes (e.g. for traffic) but can be easily adapted for other purposes (e.g. training ETA algorithms).\n",
      "\n",
      "The Uber business model revolves around dispatching black cars to pick up clients. In total, GPS traces from 25,000 such pickups are used to build this dataset. Line in each trace is spaced at about 4 seconds apart. The exception is if a car is stationary, in which case we discard redundant points until the car moves again.\n",
      "\n",
      "The logs are kept as \"raw\" as possible - bad traces and/or missing data (e.g. from radio interference) is preserved. However, the logs have been altered to protect the privacy of our clients. Specifically, we truncated the start and end legs of each trace and also occluded the specific date of the pickup. Rather than their true original dates, all pickups in the dataset are shown to have started during the first week of January 2007. The weekday and time of day is preserved, however. Finally, traces deemed too short to effectively truncate have been excluded from the dataset."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This python notebook massages the Uber Dataset to only keep the start and end point of each Uber ride and some additional info about each trip. This reduces the dataset from 1128663 rows down to 24999 rows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import dateutil\n",
      "\n",
      "def parseDate(d):\n",
      "    return dateutil.parser.parse(d);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../data/all.tsv', sep='\\t');\n",
      "df['datetime'] = df['time'].apply(parseDate);\n",
      "minTrip = df['datetime'].min();\n",
      "maxTrip = df['datetime'].max();\n",
      "totalTrip = (maxTrip - minTrip).total_seconds();\n",
      "\n",
      "def normalizeTime(t):\n",
      "    tripDuration = (t - minTrip).total_seconds();\n",
      "    return tripDuration / totalTrip;\n",
      "    \n",
      "df['normTime'] = df['datetime'].apply(normalizeTime);\n",
      "df.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = [];\n",
      "\n",
      "data = {\n",
      "    'startLat' : [],\n",
      "    'startLon' : [],\n",
      "    'endLat' : [], \n",
      "    'endLon' : [],\n",
      "    'duration' : [],\n",
      "    'startTime' : []\n",
      "};\n",
      "\n",
      "for key, g in df.groupby('tripId'):\n",
      "    end = g['datetime'].max()\n",
      "    start = g['datetime'].min()\n",
      "    index.append(key);\n",
      "    data['startLat'].append(g[g['datetime'] == start]['lat'].values[0]);\n",
      "    data['startLon'].append(g[g['datetime'] == start]['lon'].values[0]);\n",
      "    data['endLat'].append(g[g['datetime'] == end]['lat'].values[0]);\n",
      "    data['endLon'].append(g[g['datetime'] == end]['lon'].values[0]);\n",
      "    data['duration'].append(end - start);\n",
      "    data['startTime'].append(start);\n",
      "    \n",
      "result = pd.DataFrame(data, index = index);\n",
      "result['dayofweek'] = result['startTime'].apply(lambda x: x.weekday());\n",
      "result.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del df[\"time\"];\n",
      "del df[\"datetime\"];\n",
      "df.to_csv(\"../data/all.csv\", sep=\",\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import dateutil\n",
      "if len(result) == 0:\n",
      "    d = pd.read_csv(\"../data/trips.csv\");\n",
      "    d['startTime'] = d['startTime'].apply(parseDate);\n",
      "    %qtconsole\n",
      "    result = d"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Produce a normalized column of rhw trip date"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "minTrip = result['startTime'].min();\n",
      "maxTrip = result['startTime'].max();\n",
      "totalTrip = (maxTrip - minTrip).total_seconds();\n",
      "\n",
      "def normalizeTime(t):\n",
      "    tripDuration = (t - minTrip).total_seconds();\n",
      "    return tripDuration / totalTrip;\n",
      "    \n",
      "result['normTime'] = result['startTime'].apply(normalizeTime);\n",
      "result.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result.to_csv(\"../data/trips.csv\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}